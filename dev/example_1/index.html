<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Example: Gaussian Mixture · KissABC.jl</title><link rel="canonical" href="https://juliaapproxinference.github.io/KissABC.jl/example_1/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">KissABC.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Basic Usage</a></li><li class="is-active"><a class="tocitem" href>Example: Gaussian Mixture</a></li><li><a class="tocitem" href="../reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Example: Gaussian Mixture</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Example: Gaussian Mixture</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaApproxInference/KissABC.jl/blob/master/docs/literate/example_1.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="A-gaussian-mixture-model-1"><a class="docs-heading-anchor" href="#A-gaussian-mixture-model-1">A gaussian mixture model</a><a class="docs-heading-anchor-permalink" href="#A-gaussian-mixture-model-1" title="Permalink"></a></h1><p>First of all we define our model,</p><pre><code class="language-julia">using KissABC
using Distributions

function model(P, N)
    μ_1, μ_2, σ_1, σ_2, prob = P
    d1 = randn(N) .* σ_1 .+ μ_1
    d2 = randn(N) .* σ_2 .+ μ_2
    ps = rand(N) .&lt; prob
    R = zeros(N)
    R[ps] .= d1[ps]
    R[.!ps] .= d2[.!ps]
    R
end</code></pre><pre><code class="language-none">model (generic function with 1 method)</code></pre><p>Let&#39;s use the model to generate some data, this data will constitute our dataset</p><pre><code class="language-julia">parameters = (1.0, 0.0, 0.2, 2.0, 0.4)
data = model(parameters, 5000)</code></pre><pre><code class="language-none">5000-element Array{Float64,1}:
  1.299229908237814
  1.068631630302492
  1.1303080604973088
  0.8966586026497546
  1.4920157684593787
 -0.4777327997797667
  0.8760212256166288
  0.7911662475694704
  1.193923076930077
  0.804127526140622
  ⋮
  0.820501178457144
  0.7843801261831735
  0.8913765815387986
  0.16736312723082875
  0.8382090672410678
  1.2416848032727128
  2.090919327269665
  0.6696885869379728
  0.7866495739200836</code></pre><p>let&#39;s look at the data</p><pre><code class="language-julia">using Plots
histogram(data)
savefig(&quot;ex1_hist1.svg&quot;);</code></pre><p><img src="../ex1_hist1.svg" alt="ex1_hist1"/></p><p>we can now try to infer all parameters using <code>KissABC</code>, first of all we need to define a reasonable prior for our model</p><pre><code class="language-julia">prior = Factored(
    Uniform(0, 2), # there is surely a peak between 0 and 2
    Uniform(-1, 1), #there is a smeared distribution centered around 0
    Uniform(0, 1), # the peak has surely a width below 1
    Uniform(0, 4), # the smeared distribution surely has a width less than 4
    Beta(2, 2), # the number of total events from both distributions look about the same, so we will favor 0.5 just a bit
);</code></pre><p>let&#39;s look at a sample from the prior, to see that it works</p><pre><code class="language-julia">rand(prior)</code></pre><pre><code class="language-none">(1.402221692981155, -0.9402855331519158, 0.8027024775072362, 1.849783408984286, 0.12259114226085029)</code></pre><p>now we need a function to compute summary statistics for our data, this is not the optimal choice, but it will work out anyway</p><pre><code class="language-julia">function S(x)
    r = (0.1, 0.2, 0.5, 0.8, 0.9)
    quantile(x, r)
end</code></pre><pre><code class="language-none">S (generic function with 1 method)</code></pre><p>we will define a function to use the <code>model</code> and summarize it&#39;s results</p><pre><code class="language-julia">summ_model(P, N) = S(model(P, N));</code></pre><p>now we need a distance function to compare the summary statistics of target data and simulated data</p><pre><code class="language-julia">summ_data = S(data)
D(P, N = 5000) = sqrt(mean(abs2, summ_data .- summ_model(P, N)));</code></pre><p>we can now run ABCDE to get the posterior distribution of our parameters given the dataset <code>data</code></p><pre><code class="language-julia">approx_density = ApproxPosterior(prior, D, 0.05)
res, _ = mcmc(approx_density, nparticles = 100, generations = 500, verbose = 0)</code></pre><pre><code class="language-none">([(0.9952727730284217, -0.08520375034561671, 0.26572053362550774, 1.9285874245460841, 0.40733434864424456), (0.9521143988413334, 0.005694787203535237, 0.21206166322333647, 2.1292194059884624, 0.44000125505966325), (1.0209315256551355, 0.05490249521088396, 0.27699975083563294, 2.0102625267699303, 0.4141909833595851), (1.01615221341502, -0.08995051456858233, 0.1614094787927982, 1.866139610982947, 0.39779693007614786), (1.0282614382006943, 0.024675016641441207, 0.20093105466937972, 1.9326248328400117, 0.3617462631946477), (1.0541931009935375, -0.03472434927665358, 0.21677696628519427, 1.8912568793951543, 0.3915237320763668), (1.0238475950462864, -0.07568294240468615, 0.20117055017237795, 1.9674623364142794, 0.3967044360765065), (0.9612242643548801, -0.06251013757263889, 0.29974326371415916, 1.986059698907288, 0.41274226014963766), (0.9741949260559934, -0.06691751705034157, 0.19891711247413904, 1.9353159701771148, 0.393426513405707), (0.98265009425028, -0.0072962829704912024, 0.19592607488073294, 2.050296249988135, 0.4233859851499745)  …  (1.076613523056653, 0.008703645994225101, 0.1490574176501499, 1.9112819230233093, 0.36229031542916645), (0.9990619125842319, -0.002729670732143523, 0.22028176632452223, 1.9396924562315525, 0.38843053815842943), (1.0150083486666768, -0.017225075502794326, 0.13212342331921217, 1.9207402827865943, 0.38830731732499907), (1.0554911520965773, -0.02010059368371319, 0.20036503496982067, 1.9412630938845181, 0.3472224298508805), (0.9366182373348073, -0.10323116523475355, 0.2645261214662678, 2.272988041531848, 0.44953628269213486), (1.0425568326826742, -0.005980929783395129, 0.1685368891157043, 1.7781316820350357, 0.31652727634787453), (0.9848347873474543, -0.015355072157801013, 0.21533235713644022, 1.926790652603331, 0.3784834826953598), (0.9937099528538549, 0.10768258056511176, 0.21094254314906394, 2.045584713859639, 0.4186256950878894), (1.056437271916786, -0.0012540174932597556, 0.12801719856570493, 1.824106734319514, 0.29018884561147557), (1.0323359260745908, -0.07191633116200219, 0.20753694737828535, 2.0894697267367337, 0.4117067955981534)], NamedTuple{(:logprior, :cost),Tuple{Float64,Float64}}[(logprior = -2.402075053054447, cost = 0.04394787738309398), (logprior = -2.3816276891107226, cost = 0.04875045316911036), (logprior = -2.3970188047729906, cost = 0.04754192536231501), (logprior = -2.409803447958152, cost = 0.04857800924400351), (logprior = -2.446660864446372, cost = 0.03440493275985621), (logprior = -2.415335768332088, cost = 0.029440512369406154), (logprior = -2.4107410686713453, cost = 0.04766003688393744), (logprior = -2.398052676986408, cost = 0.043724650305056664), (logprior = -2.413619625671183, cost = 0.03801671658916219), (logprior = -2.390882462628309, cost = 0.04599792172133858)  …  (logprior = -2.446010804312637, cost = 0.04837136980651395), (logprior = -2.418196910891442, cost = 0.049664056618179), (logprior = -2.418312726001674, cost = 0.04234122344130931), (logprior = -2.465137784564705, cost = 0.04168162922920168), (logprior = -2.377362197054115, cost = 0.05710118705661579), (logprior = -2.511743643416797, cost = 0.04042624614007734), (logprior = -2.428004890786945, cost = 0.03695623506117231), (logprior = -2.393967827505458, cost = 0.04427413458488575), (logprior = -2.5608089532431215, cost = 0.04727824176066671), (logprior = -2.3988029055895512, cost = 0.03520181760637699)])</code></pre><p>let&#39;s see the median and 95% confidence interval for the inferred parameters and let&#39;s compare them with the true values</p><pre><code class="language-julia">getstats(V) =
    (median = median(V), lowerbound = quantile(V, 0.025), upperbound = quantile(V, 0.975));

labels = (:μ_1, :μ_2, :σ_1, :σ_2, :prob)
P = [getindex.(res, i) for i = 1:5]
stats = getstats.(P)

for is in eachindex(stats)
    println(labels[is], &quot; ≡ &quot;, parameters[is], &quot; → &quot;, stats[is])
end</code></pre><pre><code class="language-none">μ_1 ≡ 1.0 → (median = 1.0017808859013166, lowerbound = 0.9222992460158616, upperbound = 1.0976832990289505)
μ_2 ≡ 0.0 → (median = -0.007897603313937252, lowerbound = -0.415140373449596, upperbound = 0.08264242851713319)
σ_1 ≡ 0.2 → (median = 0.202773404614234, lowerbound = 0.12693547293835453, upperbound = 0.4290904292241164)
σ_2 ≡ 2.0 → (median = 1.9306061286930478, lowerbound = 1.7619645177469032, upperbound = 2.222038104682886)
prob ≡ 0.4 → (median = 0.3834145619616455, lowerbound = 0.29630852083623066, upperbound = 0.5111599091826705)</code></pre><p>The inferred parameters are close to nominal values</p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Basic Usage</a><a class="docs-footer-nextpage" href="../reference/">Reference »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Tuesday 30 June 2020 05:22">Tuesday 30 June 2020</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
