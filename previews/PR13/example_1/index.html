<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Example: Gaussian Mixture · KissABC.jl</title><link rel="canonical" href="https://juliaapproxinference.github.io/KissABC.jl/example_1/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">KissABC.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Basic Usage</a></li><li class="is-active"><a class="tocitem" href>Example: Gaussian Mixture</a></li><li><a class="tocitem" href="../reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Example: Gaussian Mixture</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Example: Gaussian Mixture</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaApproxInference/KissABC.jl/blob/master/docs/literate/example_1.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="A-gaussian-mixture-model-1"><a class="docs-heading-anchor" href="#A-gaussian-mixture-model-1">A gaussian mixture model</a><a class="docs-heading-anchor-permalink" href="#A-gaussian-mixture-model-1" title="Permalink"></a></h1><p>First of all we define our model,</p><pre><code class="language-julia">using KissABC
using Distributions

function model(P, N)
    μ_1, μ_2, σ_1, σ_2, prob = P
    d1 = randn(N) .* σ_1 .+ μ_1
    d2 = randn(N) .* σ_2 .+ μ_2
    ps = rand(N) .&lt; prob
    R = zeros(N)
    R[ps] .= d1[ps]
    R[.!ps] .= d2[.!ps]
    R
end</code></pre><pre><code class="language-none">model (generic function with 1 method)</code></pre><p>Let&#39;s use the model to generate some data, this data will constitute our dataset</p><pre><code class="language-julia">parameters = (1.0, 0.0, 0.2, 2.0, 0.4)
data = model(parameters, 5000)</code></pre><pre><code class="language-none">5000-element Array{Float64,1}:
 -1.3836410723066483
  0.9495663345993833
  0.798232310989764
  1.0844029567041882
  0.9915757060272398
  1.0980716962685335
 -2.0487754435730405
  1.2870504219529129
  0.6924017780769759
  1.2578803069648261
  ⋮
  0.69838569541751
  0.7839965606841428
  1.1870905117895019
  0.6644751812666012
  0.9921649588272486
  1.0950030994363997
  0.7349044037217818
  0.6499040080121605
  3.493342538307059</code></pre><p>let&#39;s look at the data</p><pre><code class="language-julia">using Plots
histogram(data)
savefig(&quot;ex1_hist1.svg&quot;);</code></pre><p><img src="../ex1_hist1.svg" alt="ex1_hist1"/></p><p>we can now try to infer all parameters using <code>KissABC</code>, first of all we need to define a reasonable prior for our model</p><pre><code class="language-julia">prior = Factored(
    Uniform(0, 2), # there is surely a peak between 0 and 2
    Uniform(-1, 1), #there is a smeared distribution centered around 0
    Uniform(0, 1), # the peak has surely a width below 1
    Uniform(0, 4), # the smeared distribution surely has a width less than 4
    Beta(2, 2), # the number of total events from both distributions look about the same, so we will favor 0.5 just a bit
);</code></pre><p>let&#39;s look at a sample from the prior, to see that it works</p><pre><code class="language-julia">rand(prior)</code></pre><pre><code class="language-none">(0.4380640617090097, 0.5597751030245743, 0.7265475718207579, 0.37523716739879376, 0.37736486025316546)</code></pre><p>now we need a function to compute summary statistics for our data, this is not the optimal choice, but it will work out anyway</p><pre><code class="language-julia">function S(x)
    r = (0.1, 0.2, 0.5, 0.8, 0.9)
    quantile(x, r)
end</code></pre><pre><code class="language-none">S (generic function with 1 method)</code></pre><p>we will define a function to use the <code>model</code> and summarize it&#39;s results</p><pre><code class="language-julia">summ_model(P, N) = S(model(P, N));</code></pre><p>now we need a distance function to compare the summary statistics of target data and simulated data</p><pre><code class="language-julia">summ_data = S(data)
D(P, N = 5000) = sqrt(mean(abs2, summ_data .- summ_model(P, N)));</code></pre><p>we can now run ABCDE to get the posterior distribution of our parameters given the dataset <code>data</code></p><pre><code class="language-julia">approx_density = ApproxPosterior(prior, D, 0.05)
res, _ = mcmc(approx_density, nparticles = 100, generations = 500, verbose = 0)</code></pre><pre><code class="language-none">([(1.174281817360683, -0.8874348919329345, 0.6492185773507839, 1.6095428349139924, 0.598498904448191), (0.9231544151372914, 0.14561964101628744, 0.2207579882951693, 1.9430752247432217, 0.347232474370935), (1.0372245316746072, 0.07244996890479424, 0.17379910746042715, 2.014954026329328, 0.406979763697221), (1.1020829817413713, 0.11333770451623171, 0.13874010762006656, 1.7730399431770771, 0.28291884250698357), (0.9549005711472023, -0.016533690685986105, 0.24167533473294633, 2.0841163708808996, 0.39933057238046893), (1.0268584520044761, 0.0743663108439668, 0.23743323552305445, 1.9478722572403497, 0.3869713366355654), (0.9675786127300039, 0.14060182596195728, 0.16717250256282878, 1.9795153323945993, 0.38023458009890165), (0.9829649399008, 0.07122392378386679, 0.23670622570118985, 1.998904500387769, 0.3845669418678096), (1.0725610716622211, 0.09331252519018704, 0.18389822056479577, 1.8349618199248041, 0.3090854150513139), (1.0255354105266667, 0.019893608838980475, 0.18101096492090843, 2.027763273327615, 0.350592973012479)  …  (0.98640298492003, 0.017761186517256916, 0.21171334391887095, 1.9642322558721266, 0.36868066711673586), (1.054073029774996, 0.11897690844216896, 0.17908264193081866, 1.922568930800844, 0.35325008387391893), (1.0629191766076942, 0.08631954577157014, 0.20635240669418534, 1.8933489893930666, 0.34849567853623237), (0.9423330997304049, 0.1390367235923792, 0.1692083290543811, 1.862031904229877, 0.2968744283827061), (1.0798692804762153, 0.1331671691909328, 0.20440429669045596, 1.9919166618764668, 0.3580594790136535), (1.0163510779884541, 0.13260405016660518, 0.18962320792188164, 1.9136415884143225, 0.3900815461441508), (0.9295040805950444, 0.12008020853842774, 0.24889047195528385, 1.8918441085793654, 0.3504272963731297), (1.0732445542110374, 0.07677686358118137, 0.1592306696146823, 1.8879191523327488, 0.3371659503039989), (1.0690761291591364, 0.02194056479791512, 0.18674538710973437, 1.8945365373267, 0.34956286864415603), (1.0431518274142995, 0.08451646126632131, 0.15436402552423226, 1.8841355823823778, 0.31321492267997825)], NamedTuple{(:logprior, :cost),Tuple{Float64,Float64}}[(logprior = -2.4067048544453797, cost = 0.14026021963005322), (logprior = -2.46512424425581, cost = 0.04871743540640799), (logprior = -2.4023478236998996, cost = 0.04224388027750269), (logprior = -2.575990705493541, cost = 0.04727480365546743), (logprior = -2.408505488927437, cost = 0.045268856770714065), (logprior = -2.419577492228398, cost = 0.046131204899786164), (logprior = -2.426210381220404, cost = 0.03673898078910354), (logprior = -2.421895756530475, cost = 0.04221915279895981), (logprior = -2.524705942818227, cost = 0.040389028417366586), (logprior = -2.460654201089323, cost = 0.048965734190580174)  …  (logprior = -2.4385971335498042, cost = 0.03616506994658369), (logprior = -2.457203860595471, cost = 0.03664964475102761), (logprior = -2.4634299513937354, cost = 0.02521073089529161), (logprior = -2.5474950632774025, cost = 0.04884428324131234), (logprior = -2.451145042919895, cost = 0.04939649514172969), (logprior = -2.4166587350042565, cost = 0.03893796330225024), (logprior = -2.460871786653853, cost = 0.0470925636199841), (logprior = -2.47923991095563, cost = 0.03498575421464378), (logprior = -2.462011737172961, cost = 0.044724929951901415), (logprior = -2.5174288011971067, cost = 0.02696296743333908)])</code></pre><p>let&#39;s see the median and 95% confidence interval for the inferred parameters and let&#39;s compare them with the true values</p><pre><code class="language-julia">getstats(V) =
    (median = median(V), lowerbound = quantile(V, 0.025), upperbound = quantile(V, 0.975));

labels = (:μ_1, :μ_2, :σ_1, :σ_2, :prob)
P = [getindex.(res, i) for i = 1:5]
stats = getstats.(P)

for is in eachindex(stats)
    println(labels[is], &quot; ≡ &quot;, parameters[is], &quot; → &quot;, stats[is])
end</code></pre><pre><code class="language-none">μ_1 ≡ 1.0 → (median = 1.0273208332639323, lowerbound = 0.9237959169382908, upperbound = 1.194282720193877)
μ_2 ≡ 0.0 → (median = 0.0940779361543683, lowerbound = -0.42420872678097465, upperbound = 0.19265373267258762)
σ_1 ≡ 0.2 → (median = 0.18442272905209695, lowerbound = 0.05274138368579275, upperbound = 0.599779192362295)
σ_2 ≡ 2.0 → (median = 1.914585200825444, lowerbound = 1.6401595372332096, upperbound = 2.103861470039923)
prob ≡ 0.4 → (median = 0.35480508906080954, lowerbound = 0.25532074453918374, upperbound = 0.5727729918951834)</code></pre><p>The inferred parameters are close to nominal values</p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Basic Usage</a><a class="docs-footer-nextpage" href="../reference/">Reference »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Sunday 28 June 2020 17:39">Sunday 28 June 2020</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
