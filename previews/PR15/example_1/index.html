<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Example: Gaussian Mixture · KissABC.jl</title><link rel="canonical" href="https://juliaapproxinference.github.io/KissABC.jl/example_1/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">KissABC.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Basic Usage</a></li><li class="is-active"><a class="tocitem" href>Example: Gaussian Mixture</a></li><li><a class="tocitem" href="../reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Example: Gaussian Mixture</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Example: Gaussian Mixture</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaApproxInference/KissABC.jl/blob/master/docs/literate/example_1.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="A-gaussian-mixture-model"><a class="docs-heading-anchor" href="#A-gaussian-mixture-model">A gaussian mixture model</a><a id="A-gaussian-mixture-model-1"></a><a class="docs-heading-anchor-permalink" href="#A-gaussian-mixture-model" title="Permalink"></a></h1><p>First of all we define our model,</p><pre><code class="language-julia">using KissABC
using Distributions

function model(P, N)
    μ_1, μ_2, σ_1, σ_2, prob = P
    d1 = randn(N) .* σ_1 .+ μ_1
    d2 = randn(N) .* σ_2 .+ μ_2
    ps = rand(N) .&lt; prob
    R = zeros(N)
    R[ps] .= d1[ps]
    R[.!ps] .= d2[.!ps]
    R
end</code></pre><pre><code class="language-none">model (generic function with 1 method)</code></pre><p>Let&#39;s use the model to generate some data, this data will constitute our dataset</p><pre><code class="language-julia">parameters = (1.0, 0.0, 0.2, 2.0, 0.4)
data = model(parameters, 5000)</code></pre><pre><code class="language-none">5000-element Array{Float64,1}:
  1.054865923279867
  0.43637968352895434
  3.3080486970134277
  3.527163926924321
  0.728695093703604
  1.0644768939802691
 -3.1629134724706787
  1.0414177140006846
  1.581968997596491
  1.1326372379532665
  ⋮
  0.7132952281786271
  1.2382005009266446
  0.9487593813326513
 -0.5882471522882255
  0.6103926574508278
  1.1988807071284495
  0.617254699943829
  1.9921039587305027
  1.166871026504361</code></pre><p>let&#39;s look at the data</p><pre><code class="language-julia">using Plots
histogram(data)
savefig(&quot;ex1_hist1.svg&quot;);</code></pre><p><img src="../ex1_hist1.svg" alt="ex1_hist1"/></p><p>we can now try to infer all parameters using <code>KissABC</code>, first of all we need to define a reasonable prior for our model</p><pre><code class="language-julia">prior = Factored(
    Uniform(0, 2), # there is surely a peak between 0 and 2
    Uniform(-1, 1), #there is a smeared distribution centered around 0
    Uniform(0, 1), # the peak has surely a width below 1
    Uniform(0, 4), # the smeared distribution surely has a width less than 4
    Beta(2, 2), # the number of total events from both distributions look about the same, so we will favor 0.5 just a bit
);</code></pre><p>let&#39;s look at a sample from the prior, to see that it works</p><pre><code class="language-julia">rand(prior)</code></pre><pre><code class="language-none">(1.2555020526285294, 0.5101681630360457, 0.1291298461454944, 2.3546475713941453, 0.516450922095902)</code></pre><p>now we need a function to compute summary statistics for our data, this is not the optimal choice, but it will work out anyway</p><pre><code class="language-julia">function S(x)
    r = (0.1, 0.2, 0.5, 0.8, 0.9)
    quantile(x, r)
end</code></pre><pre><code class="language-none">S (generic function with 1 method)</code></pre><p>we will define a function to use the <code>model</code> and summarize it&#39;s results</p><pre><code class="language-julia">summ_model(P, N) = S(model(P, N));</code></pre><p>now we need a distance function to compare the summary statistics of target data and simulated data</p><pre><code class="language-julia">summ_data = S(data)
D(P, N = 5000) = sqrt(mean(abs2, summ_data .- summ_model(P, N)));</code></pre><p>we can now run ABCDE to get the posterior distribution of our parameters given the dataset <code>data</code></p><pre><code class="language-julia">approx_density = ApproxPosterior(prior, D, 0.05)
res, _ = mcmc(approx_density, nparticles = 100, generations = 500, verbose = 0)</code></pre><pre><code class="language-none">([(0.9838575019386233, 0.17712051001569495, 0.19559219778887926, 2.087010696821269, 0.3977033990193356), (1.0156045477771227, 0.07136140578429304, 0.21507484342380603, 1.9661235171977631, 0.3756280143295458), (1.0349843600880992, 0.14010035906293777, 0.10246847784628932, 1.8910175329188446, 0.3253655985884095), (0.9682449033364898, 0.1722405440499625, 0.20107548324987823, 1.9178485942630223, 0.3423334742831283), (0.956612659784412, 0.1954382478368611, 0.18392769239306958, 2.0381766012576397, 0.37074541846640474), (1.0520501306308383, 0.06376868131933335, 0.1980722931747017, 1.88615067615747, 0.3505059513972501), (1.0417825115497958, 0.10684872358424152, 0.23306919837977644, 1.8768832302465468, 0.33233694976360084), (0.9550637529431703, 0.10282842879779996, 0.12324639292018397, 1.9680310838875181, 0.36397616138261457), (1.0396619386539747, 0.1585939415943321, 0.1722639861818693, 1.9016437313149177, 0.3201955040412988), (1.0027575510139966, 0.14743245949269382, 0.11151203257417402, 1.9722977890620823, 0.35078940321584473)  …  (1.0176510393366065, 0.06089939968697905, 0.1339196862996915, 1.9096269509460115, 0.3516123840053933), (1.0362890969115544, 0.033050198157407576, 0.1317065509169445, 1.9552150835516808, 0.37160765531333545), (0.9653894836190727, 0.05013798258180731, 0.2661399818693904, 2.0204226647887977, 0.35988004082150327), (1.0909059427014653, 0.05704884801943669, 0.17235257998667938, 1.9924935272142557, 0.37711508150912), (1.0181822265230998, 0.09837544579747877, 0.1055830637330129, 1.9315849302338974, 0.3238614309438399), (0.9387564305238194, 0.13629185380452902, 0.22824148114073273, 2.029008883994651, 0.35427649244423765), (1.0075190209285894, 0.06330017079266584, 0.1923582695566159, 1.9294955165200294, 0.34953634788089677), (1.0712614237921685, 0.04392567512605407, 0.14658826893878082, 1.9714100929958462, 0.3940291157295586), (0.907899332189229, 0.14500968195607095, 0.05593889942606316, 1.8651803749188651, 0.2778000927681228), (0.9119354983117143, 0.17061960020221834, 0.08457472708698643, 1.8316095960228784, 0.3024839510448112)], NamedTuple{(:logprior, :cost),Tuple{Float64,Float64}}[(logprior = -2.409883295472506, cost = 0.04246750534038766), (logprior = -2.430994159245198, cost = 0.04358426488018041), (logprior = -2.4972194255587024, cost = 0.04052369610812705), (logprior = -2.4718564749465344, cost = 0.04634612280093763), (logprior = -2.436288272576352, cost = 0.0446847640017541), (logprior = -2.460768451885723, cost = 0.04367613540456038), (logprior = -2.4864068173424485, cost = 0.049467683645752776), (logprior = -2.4440153914504794, cost = 0.047900339294120686), (logprior = -2.505602800717911, cost = 0.04896185760583847), (logprior = -2.4603966000729987, cost = 0.036277489926078536)  …  (logprior = -2.4593217335775086, cost = 0.04695161112831879), (logprior = -2.4353364792204077, cost = 0.03735817293363669), (logprior = -2.448913459990068, cost = 0.04836124733288264), (logprior = -2.429427633915896, cost = 0.04567823063125152), (logprior = -2.4996260300903765, cost = 0.04321423991382433), (logprior = -2.455890745320432, cost = 0.04667687141743253), (logprior = -2.462046835493699, cost = 0.048487500746380426), (logprior = -2.4130830674608834, cost = 0.045479620251175704), (logprior = -2.587136066326059, cost = 0.04608258371194241), (logprior = -2.536786066624294, cost = 0.045433442118885524)])</code></pre><p>let&#39;s see the median and 95% confidence interval for the inferred parameters and let&#39;s compare them with the true values</p><pre><code class="language-julia">getstats(V) =
    (median = median(V), lowerbound = quantile(V, 0.025), upperbound = quantile(V, 0.975));

labels = (:μ_1, :μ_2, :σ_1, :σ_2, :prob)
P = [getindex.(res, i) for i = 1:5]
stats = getstats.(P)

for is in eachindex(stats)
    println(labels[is], &quot; ≡ &quot;, parameters[is], &quot; → &quot;, stats[is])
end</code></pre><pre><code class="language-none">μ_1 ≡ 1.0 → (median = 0.9979411163834055, lowerbound = 0.9092773050100903, upperbound = 1.0872754485115732)
μ_2 ≡ 0.0 → (median = 0.08366110193747081, lowerbound = -0.0460042797693081, upperbound = 0.18548856884998877)
σ_1 ≡ 0.2 → (median = 0.18451832230220672, lowerbound = 0.08267869702973313, upperbound = 0.4620437751591129)
σ_2 ≡ 2.0 → (median = 1.9647270006226676, lowerbound = 1.8273312580238446, upperbound = 2.169516327325662)
prob ≡ 0.4 → (median = 0.36451499411248095, lowerbound = 0.2970037469086636, upperbound = 0.48484834895465706)</code></pre><p>The inferred parameters are close to nominal values</p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Basic Usage</a><a class="docs-footer-nextpage" href="../reference/">Reference »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Tuesday 30 June 2020 23:27">Tuesday 30 June 2020</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
