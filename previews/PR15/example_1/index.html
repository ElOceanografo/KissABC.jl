<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Example: Gaussian Mixture · KissABC.jl</title><link rel="canonical" href="https://juliaapproxinference.github.io/KissABC.jl/example_1/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">KissABC.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Basic Usage</a></li><li class="is-active"><a class="tocitem" href>Example: Gaussian Mixture</a></li><li><a class="tocitem" href="../reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Example: Gaussian Mixture</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Example: Gaussian Mixture</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaApproxInference/KissABC.jl/blob/master/docs/literate/example_1.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="A-gaussian-mixture-model"><a class="docs-heading-anchor" href="#A-gaussian-mixture-model">A gaussian mixture model</a><a id="A-gaussian-mixture-model-1"></a><a class="docs-heading-anchor-permalink" href="#A-gaussian-mixture-model" title="Permalink"></a></h1><p>First of all we define our model,</p><pre><code class="language-julia">using KissABC
using Distributions

function model(P, N)
    μ_1, μ_2, σ_1, σ_2, prob = P
    d1 = randn(N) .* σ_1 .+ μ_1
    d2 = randn(N) .* σ_2 .+ μ_2
    ps = rand(N) .&lt; prob
    R = zeros(N)
    R[ps] .= d1[ps]
    R[.!ps] .= d2[.!ps]
    R
end</code></pre><pre><code class="language-none">model (generic function with 1 method)</code></pre><p>Let&#39;s use the model to generate some data, this data will constitute our dataset</p><pre><code class="language-julia">parameters = (1.0, 0.0, 0.2, 2.0, 0.4)
data = model(parameters, 5000)</code></pre><pre><code class="language-none">5000-element Array{Float64,1}:
 -3.29171644773515
  0.3992637519106526
  2.108214797860283
  0.9637274303802996
  1.4604090323470917
 -2.2782998024617314
  1.1864731240173394
  0.5625825340118407
  3.035596758478963
  1.1198231371163818
  ⋮
  0.9707402535238762
 -1.2897907765933576
  2.4241773088461964
 -3.205136149372341
 -1.7064603672797103
  0.605320490288008
 -2.5283417682161256
  1.1090285964351527
  0.8995944218262857</code></pre><p>let&#39;s look at the data</p><pre><code class="language-julia">using Plots
histogram(data)
savefig(&quot;ex1_hist1.svg&quot;);</code></pre><p><img src="../ex1_hist1.svg" alt="ex1_hist1"/></p><p>we can now try to infer all parameters using <code>KissABC</code>, first of all we need to define a reasonable prior for our model</p><pre><code class="language-julia">prior = Factored(
    Uniform(0, 2), # there is surely a peak between 0 and 2
    Uniform(-1, 1), #there is a smeared distribution centered around 0
    Uniform(0, 1), # the peak has surely a width below 1
    Uniform(0, 4), # the smeared distribution surely has a width less than 4
    Beta(2, 2), # the number of total events from both distributions look about the same, so we will favor 0.5 just a bit
);</code></pre><p>let&#39;s look at a sample from the prior, to see that it works</p><pre><code class="language-julia">rand(prior)</code></pre><pre><code class="language-none">(1.1762005617880322, 0.490905598528371, 0.03419123328794704, 3.223551626990508, 0.3076565172729685)</code></pre><p>now we need a function to compute summary statistics for our data, this is not the optimal choice, but it will work out anyway</p><pre><code class="language-julia">function S(x)
    r = (0.1, 0.2, 0.5, 0.8, 0.9)
    quantile(x, r)
end</code></pre><pre><code class="language-none">S (generic function with 1 method)</code></pre><p>we will define a function to use the <code>model</code> and summarize it&#39;s results</p><pre><code class="language-julia">summ_model(P, N) = S(model(P, N));</code></pre><p>now we need a distance function to compare the summary statistics of target data and simulated data</p><pre><code class="language-julia">summ_data = S(data)
D(P, N = 5000) = sqrt(mean(abs2, summ_data .- summ_model(P, N)));</code></pre><p>we can now run ABCDE to get the posterior distribution of our parameters given the dataset <code>data</code></p><pre><code class="language-julia">approx_density = ApproxPosterior(prior, D, 0.05)
res, _ = mcmc(approx_density, nparticles = 100, generations = 500, verbose = 0)</code></pre><pre><code class="language-none">([(1.0194111772351384, 0.021139550327257218, 0.24388952013765733, 1.9091765491278827, 0.4033071107896379), (0.9680852978354239, 0.008750640604871435, 0.203967652147349, 1.9047922786163651, 0.40074312646899934), (0.9621904497113443, -0.07734356755161129, 0.21873716184023909, 1.9453656514520985, 0.4158246890946714), (1.0446246240182795, -0.07547657643771949, 0.21597229728121897, 2.014079859685152, 0.4145573930599377), (0.9686062930037013, 0.024636505140355147, 0.189990995689105, 1.931985228805293, 0.39347923442615457), (1.0644243119527068, -0.018475849239868856, 0.262532506237734, 1.9205247198677873, 0.3990002500504987), (1.067544150556237, 0.04748460039433157, 0.16497117870696112, 1.8792998928496898, 0.39397116951245564), (0.9881694078254971, -0.06065194588760756, 0.17212449903375546, 1.8677979053874003, 0.4100209224245208), (1.0056419940612713, 0.09248632798197076, 0.16671094524292634, 1.9095755999594146, 0.3662527827741519), (1.001319610377, -0.032503382306966325, 0.18748754486718458, 1.9158791360528684, 0.38719401240276274)  …  (1.0260483818811885, 0.00010458796204951153, 0.17164670433791965, 1.8465700755009808, 0.3394459100047539), (1.037144373554241, 0.010597470916759662, 0.19855113103317432, 1.7948430946569924, 0.3724602994588247), (0.9720493791720788, 0.13849628122991464, 0.122214585630942, 1.9076344918080794, 0.3915810477414154), (0.9881535847960876, -0.03560964162438847, 0.20094430959005888, 2.1212668944769333, 0.437452480995666), (0.9992562060892217, 0.020927059855329513, 0.1768865602561898, 2.162634241967257, 0.4693689725046002), (1.0227889891881226, 0.06035245436661312, 0.18803663024655642, 1.8177544246160282, 0.34053127308013786), (1.0672844638833505, -0.6081635761927318, 0.5285593733925465, 1.9309825153905913, 0.5758407531807911), (0.9869093369878233, -0.0376197140501147, 0.2425519767342304, 1.8867005348929444, 0.38051974044785536), (1.0692073493930412, 0.08248906444756224, 0.12621138148830915, 1.8148363941466699, 0.3466229746012621), (1.0191298260051935, 0.04174612049323174, 0.1719542475501524, 1.9283166843496118, 0.3892183744409968)], NamedTuple{(:logprior, :cost),Tuple{Float64,Float64}}[(logprior = -2.405238920139764, cost = 0.0449403459932008), (logprior = -2.407328827830063, cost = 0.03592676398560214), (logprior = -2.3958749322961532, cost = 0.041938720797271865), (logprior = -2.396760228412981, cost = 0.048268000970507985), (logprior = -2.4135725498100142, cost = 0.03400072162309023), (logprior = -2.4087832489156353, cost = 0.04448764629725778), (logprior = -2.4131345181820447, cost = 0.04078208273052404), (logprior = -2.400044547741432, cost = 0.04130132046347882), (logprior = -2.441365888724804, cost = 0.05442417179768529), (logprior = -2.4193655302671178, cost = 0.018681219347790125)  …  (logprior = -2.4759461860817122, cost = 0.03613393990434325), (logprior = -2.4344024206710015, cost = 0.04172059516526718), (logprior = -2.4152835875901006, cost = 0.04209795164493044), (logprior = -2.3828961172039844, cost = 0.045491544962429714), (logprior = -2.370883713836262, cost = 0.049587369023583724), (logprior = -2.474398293367477, cost = 0.03417323932842845), (logprior = -2.3903996918378465, cost = 0.10424565728851992), (logprior = -2.425920919304755, cost = 0.04370485502231549), (logprior = -2.465947813325104, cost = 0.04029699529470477), (logprior = -2.417459760674484, cost = 0.020827755901432543)])</code></pre><p>let&#39;s see the median and 95% confidence interval for the inferred parameters and let&#39;s compare them with the true values</p><pre><code class="language-julia">getstats(V) =
    (median = median(V), lowerbound = quantile(V, 0.025), upperbound = quantile(V, 0.975));

labels = (:μ_1, :μ_2, :σ_1, :σ_2, :prob)
P = [getindex.(res, i) for i = 1:5]
stats = getstats.(P)

for is in eachindex(stats)
    println(labels[is], &quot; ≡ &quot;, parameters[is], &quot; → &quot;, stats[is])
end</code></pre><pre><code class="language-none">μ_1 ≡ 1.0 → (median = 1.012937211264001, lowerbound = 0.8187156101018924, upperbound = 1.0980582350523678)
μ_2 ≡ 0.0 → (median = 0.0018486010672602367, lowerbound = -0.8659841020593324, upperbound = 0.10043768441511391)
σ_1 ≡ 0.2 → (median = 0.2046144684640132, lowerbound = 0.1139368528533602, upperbound = 0.6450899861571935)
σ_2 ≡ 2.0 → (median = 1.9159910469158985, lowerbound = 1.6759649224412043, upperbound = 2.169123269842993)
prob ≡ 0.4 → (median = 0.40074622056237696, lowerbound = 0.32665811176252135, upperbound = 0.63642451222407)</code></pre><p>The inferred parameters are close to nominal values</p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Basic Usage</a><a class="docs-footer-nextpage" href="../reference/">Reference »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Tuesday 30 June 2020 23:40">Tuesday 30 June 2020</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
