<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Example: Gaussian Mixture · KissABC.jl</title><link rel="canonical" href="https://juliaapproxinference.github.io/KissABC.jl/example_1/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">KissABC.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Basic Usage</a></li><li class="is-active"><a class="tocitem" href>Example: Gaussian Mixture</a></li><li><a class="tocitem" href="../reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Example: Gaussian Mixture</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Example: Gaussian Mixture</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaApproxInference/KissABC.jl/blob/master/docs/literate/example_1.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="A-gaussian-mixture-model"><a class="docs-heading-anchor" href="#A-gaussian-mixture-model">A gaussian mixture model</a><a id="A-gaussian-mixture-model-1"></a><a class="docs-heading-anchor-permalink" href="#A-gaussian-mixture-model" title="Permalink"></a></h1><p>First of all we define our model,</p><pre><code class="language-julia">using KissABC
using Distributions

function model(P, N)
    μ_1, μ_2, σ_1, σ_2, prob = P
    d1 = randn(N) .* σ_1 .+ μ_1
    d2 = randn(N) .* σ_2 .+ μ_2
    ps = rand(N) .&lt; prob
    R = zeros(N)
    R[ps] .= d1[ps]
    R[.!ps] .= d2[.!ps]
    R
end</code></pre><pre><code class="language-none">model (generic function with 1 method)</code></pre><p>Let&#39;s use the model to generate some data, this data will constitute our dataset</p><pre><code class="language-julia">parameters = (1.0, 0.0, 0.2, 2.0, 0.4)
data = model(parameters, 5000)</code></pre><pre><code class="language-none">5000-element Array{Float64,1}:
  1.1684170021057063
 -0.6826890308387081
  1.0263473545289892
 -1.6569678431902748
  1.2072722707300674
  1.1940777675408998
  0.8652743901545182
  0.8381342103832767
 -2.8531149271002527
 -3.4396924490353
  ⋮
  0.818439207672673
  1.0522628081559644
  1.202287381223501
 -4.18269131697571
  0.029361685561549066
  0.4258646434591253
  2.0491458169466217
  0.8117101873677266
 -0.5897749428240509</code></pre><p>let&#39;s look at the data</p><pre><code class="language-julia">using Plots
histogram(data)
savefig(&quot;ex1_hist1.svg&quot;);</code></pre><p><img src="../ex1_hist1.svg" alt="ex1_hist1"/></p><p>we can now try to infer all parameters using <code>KissABC</code>, first of all we need to define a reasonable prior for our model</p><pre><code class="language-julia">prior = Factored(
    Uniform(0, 2), # there is surely a peak between 0 and 2
    Uniform(-1, 1), #there is a smeared distribution centered around 0
    Uniform(0, 1), # the peak has surely a width below 1
    Uniform(0, 4), # the smeared distribution surely has a width less than 4
    Beta(2, 2), # the number of total events from both distributions look about the same, so we will favor 0.5 just a bit
);</code></pre><p>let&#39;s look at a sample from the prior, to see that it works</p><pre><code class="language-julia">rand(prior)</code></pre><pre><code class="language-none">(1.3575493352126875, 0.8680457073532577, 0.34279015922456724, 0.7282724417626518, 0.2741753305912395)</code></pre><p>now we need a function to compute summary statistics for our data, this is not the optimal choice, but it will work out anyway</p><pre><code class="language-julia">function S(x)
    r = (0.1, 0.2, 0.5, 0.8, 0.9)
    quantile(x, r)
end</code></pre><pre><code class="language-none">S (generic function with 1 method)</code></pre><p>we will define a function to use the <code>model</code> and summarize it&#39;s results</p><pre><code class="language-julia">summ_model(P, N) = S(model(P, N));</code></pre><p>now we need a distance function to compare the summary statistics of target data and simulated data</p><pre><code class="language-julia">summ_data = S(data)
D(P, N = 5000) = sqrt(mean(abs2, summ_data .- summ_model(P, N)));</code></pre><p>we can now run ABCDE to get the posterior distribution of our parameters given the dataset <code>data</code></p><pre><code class="language-julia">approx_density = ApproxPosterior(prior, D, 0.05)
res, _ = mcmc(approx_density, nparticles = 100, generations = 500, verbose = 0)</code></pre><pre><code class="language-none">([(0.9777916845707731, 0.015091314418861742, 0.2643687084638798, 2.0178696837443133, 0.39590174996747146), (1.0211373975648848, 0.06252996295415711, 0.15632618897580902, 1.9838418822697754, 0.4135245835186569), (1.067489485571032, 0.0017684521051663377, 0.16416731696821046, 2.022998231254507, 0.4059114843824103), (1.0350612383811701, 0.05989688196300944, 0.20444537584427344, 2.008719773702085, 0.422154919912971), (0.9788853140243953, 0.053732977715089336, 0.23334978839247103, 2.096345425092361, 0.4078347480199744), (0.9419380329709622, 0.062432071970048617, 0.2341377850424159, 2.0707753095150983, 0.42564268253419585), (1.0023849822997373, 0.0681863036307743, 0.17361525464458022, 2.001166764820628, 0.3770427810943223), (1.0891764946481404, 0.06552291683209854, 0.24928921235697227, 1.9161610785112624, 0.3817182541055888), (1.0568098045675292, 0.09282065599704797, 0.2658737345047549, 1.8466306332714366, 0.36142155422881017), (1.0444979351784582, 0.03308486380375978, 0.18514441515093932, 1.940168028058004, 0.3952807327369594)  …  (1.0352125181123983, -0.004066762931502668, 0.1484421991045499, 1.8362664247780234, 0.3167506426902609), (1.0359812743115646, 0.0685942466372612, 0.2606810119707098, 1.9280107604544885, 0.37407977932876035), (1.0298854787326974, 0.07915088665025456, 0.21398197317495088, 2.045797794816621, 0.3861825042850852), (1.003396991310966, 0.04912703103059496, 0.17286737590291784, 2.058595500856272, 0.40017193507992255), (1.0744986389621638, 0.023961138434430235, 0.15399400598348004, 2.00467880776807, 0.39724081140251233), (1.000725292518282, 0.12598188930907062, 0.23672264629326567, 1.951701752165264, 0.4066830537589941), (1.0395358282191314, 0.12136543607205509, 0.1509901664169273, 1.888473799536669, 0.35776466205340307), (0.9818545208119984, 0.07692793640550381, 0.2029693030334653, 2.0997470624658376, 0.4155795283933672), (0.9614658242410901, 0.05462741762841464, 0.20154520389103936, 2.0582062465422353, 0.4230823493511853), (1.0120601206792943, 0.1380860626442335, 0.20195055013609742, 2.085729210037808, 0.41720386862279596)], NamedTuple{(:logprior, :cost),Tuple{Float64,Float64}}[(logprior = -2.411436886324722, cost = 0.04347346927417848), (logprior = -2.3974920944151386, cost = 0.03965586977427071), (logprior = -2.4031763694542856, cost = 0.04432347604571497), (logprior = -2.3916616502939396, cost = 0.041416219848052764), (logprior = -2.4016920101918764, cost = 0.02952911886868944), (logprior = -2.389487883127802, cost = 0.03959285493623193), (logprior = -2.429503305326023, cost = 0.0310433289387869), (logprior = -2.424712776121511, cost = 0.04763478079395557), (logprior = -2.447050266280077, cost = 0.04912302013494765), (logprior = -2.4119792534370417, cost = 0.02340959385685271)  …  (logprior = -2.5113650785918793, cost = 0.04791642606922267), (logprior = -2.4326478026349827, cost = 0.048971238924814316), (logprior = -2.4203320985076466, cost = 0.04092492890645304), (logprior = -2.4078024628380863, cost = 0.01780329762577357), (logprior = -2.410279374938911, cost = 0.047371048081439895), (logprior = -2.402576931058317, cost = 0.049195130916173876), (logprior = -2.4515096027728007, cost = 0.038673832448730426), (logprior = -2.3960451015297153, cost = 0.03430040212559558), (logprior = -2.3910734350834804, cost = 0.04192489527991091), (logprior = -2.3949273787616794, cost = 0.046190140124268336)])</code></pre><p>let&#39;s see the median and 95% confidence interval for the inferred parameters and let&#39;s compare them with the true values</p><pre><code class="language-julia">getstats(V) =
    (median = median(V), lowerbound = quantile(V, 0.025), upperbound = quantile(V, 0.975));

labels = (:μ_1, :μ_2, :σ_1, :σ_2, :prob)
P = [getindex.(res, i) for i = 1:5]
stats = getstats.(P)

for is in eachindex(stats)
    println(labels[is], &quot; ≡ &quot;, parameters[is], &quot; → &quot;, stats[is])
end</code></pre><pre><code class="language-none">μ_1 ≡ 1.0 → (median = 1.008152811414254, lowerbound = 0.9186737208103795, upperbound = 1.090800989428957)
μ_2 ≡ 0.0 → (median = 0.03813616580089993, lowerbound = -0.2752938316269679, upperbound = 0.1309005207998906)
σ_1 ≡ 0.2 → (median = 0.204665471866339, lowerbound = 0.145171673057493, upperbound = 0.5654968081089861)
σ_2 ≡ 2.0 → (median = 1.994942205423421, lowerbound = 1.8002369317032683, upperbound = 2.229505561747182)
prob ≡ 0.4 → (median = 0.4055069186655161, lowerbound = 0.34079999374346254, upperbound = 0.5452597681958482)</code></pre><p>The inferred parameters are close to nominal values</p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Basic Usage</a><a class="docs-footer-nextpage" href="../reference/">Reference »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 1 July 2020 06:34">Wednesday 1 July 2020</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
