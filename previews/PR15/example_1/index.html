<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Example: Gaussian Mixture · KissABC.jl</title><link rel="canonical" href="https://juliaapproxinference.github.io/KissABC.jl/example_1/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">KissABC.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Basic Usage</a></li><li class="is-active"><a class="tocitem" href>Example: Gaussian Mixture</a></li><li><a class="tocitem" href="../reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Example: Gaussian Mixture</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Example: Gaussian Mixture</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaApproxInference/KissABC.jl/blob/master/docs/literate/example_1.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="A-gaussian-mixture-model"><a class="docs-heading-anchor" href="#A-gaussian-mixture-model">A gaussian mixture model</a><a id="A-gaussian-mixture-model-1"></a><a class="docs-heading-anchor-permalink" href="#A-gaussian-mixture-model" title="Permalink"></a></h1><p>First of all we define our model,</p><pre><code class="language-julia">using KissABC
using Distributions

function model(P, N)
    μ_1, μ_2, σ_1, σ_2, prob = P
    d1 = randn(N) .* σ_1 .+ μ_1
    d2 = randn(N) .* σ_2 .+ μ_2
    ps = rand(N) .&lt; prob
    R = zeros(N)
    R[ps] .= d1[ps]
    R[.!ps] .= d2[.!ps]
    R
end</code></pre><pre><code class="language-none">model (generic function with 1 method)</code></pre><p>Let&#39;s use the model to generate some data, this data will constitute our dataset</p><pre><code class="language-julia">parameters = (1.0, 0.0, 0.2, 2.0, 0.4)
data = model(parameters, 5000)</code></pre><pre><code class="language-none">5000-element Array{Float64,1}:
  0.9340432228106728
 -0.2508974546535999
  1.1094726141637683
  0.32092044002760056
 -0.8112844184376637
 -3.315645052460293
 -0.4788974954185975
 -2.2163419794745667
  0.8979631533836016
  1.0009316810197668
  ⋮
  0.9497224404701704
  0.5711684089714396
  2.88104438503503
  0.40248679645275753
  2.8440739720735553
  0.7938184313883726
  0.6739151566187445
  1.2312019953444464
 -0.6366172949823479</code></pre><p>let&#39;s look at the data</p><pre><code class="language-julia">using Plots
histogram(data)
savefig(&quot;ex1_hist1.svg&quot;);</code></pre><p><img src="../ex1_hist1.svg" alt="ex1_hist1"/></p><p>we can now try to infer all parameters using <code>KissABC</code>, first of all we need to define a reasonable prior for our model</p><pre><code class="language-julia">prior = Factored(
    Uniform(0, 2), # there is surely a peak between 0 and 2
    Uniform(-1, 1), #there is a smeared distribution centered around 0
    Uniform(0, 1), # the peak has surely a width below 1
    Uniform(0, 4), # the smeared distribution surely has a width less than 4
    Beta(2, 2), # the number of total events from both distributions look about the same, so we will favor 0.5 just a bit
);</code></pre><p>let&#39;s look at a sample from the prior, to see that it works</p><pre><code class="language-julia">rand(prior)</code></pre><pre><code class="language-none">(1.8527961544172458, -0.6569726408291223, 0.8549072236675135, 1.4977060904987232, 0.07344009065001737)</code></pre><p>now we need a function to compute summary statistics for our data, this is not the optimal choice, but it will work out anyway</p><pre><code class="language-julia">function S(x)
    r = (0.1, 0.2, 0.5, 0.8, 0.9)
    quantile(x, r)
end</code></pre><pre><code class="language-none">S (generic function with 1 method)</code></pre><p>we will define a function to use the <code>model</code> and summarize it&#39;s results</p><pre><code class="language-julia">summ_model(P, N) = S(model(P, N));</code></pre><p>now we need a distance function to compare the summary statistics of target data and simulated data</p><pre><code class="language-julia">summ_data = S(data)
D(P, N = 5000) = sqrt(mean(abs2, summ_data .- summ_model(P, N)));</code></pre><p>we can now run ABCDE to get the posterior distribution of our parameters given the dataset <code>data</code></p><pre><code class="language-julia">approx_density = ApproxPosterior(prior, D, 0.05)
res, _ = mcmc(approx_density, nparticles = 100, generations = 500, verbose = 0)</code></pre><pre><code class="language-none">([(1.0597757648194064, -0.7369647626732667, 0.5270979448907804, 1.7621837553068163, 0.557796405927744), (1.0346980616521222, 0.003409547056381379, 0.18723722310040072, 1.9643046861859232, 0.39274302555745094), (1.127334337629576, -0.7667165865539902, 0.4725568735481024, 1.7222503877131805, 0.5758380500148718), (1.0252756100459797, -0.11892504064190648, 0.1345698266731176, 2.0612320429090056, 0.40613447892810933), (1.0393833740191456, -0.00932848926624554, 0.17349346966105422, 2.123525504299643, 0.43512548763206604), (0.597707919911249, -0.30895198776977006, 0.8277493128085044, 3.392422838816407, 0.6748847975443449), (1.0525163305562506, -0.03503812318274932, 0.2115189355151821, 2.191133003950896, 0.41316663789447006), (1.0374778296343306, -0.011922139857464669, 0.1709543842325767, 1.9908215617121194, 0.4141075229169721), (1.0221171286951352, -0.009373096189461718, 0.19302393196919682, 1.9439676615248447, 0.3744965328858486), (1.0363217827547917, -0.025980925754730193, 0.14205489926179798, 1.9392196622216908, 0.4049444559923068)  …  (0.9677260331655262, -0.11431409192441137, 0.18015983909072236, 2.073985806049029, 0.41432925962088263), (1.0025132077304029, -0.13441067753774907, 0.13845661843375778, 2.1597601141470397, 0.4436316518901097), (1.0380722515250167, -0.03840611510870307, 0.17510754247675334, 2.088747033431649, 0.410949578083267), (1.0247726034341311, 0.004657492825908259, 0.24313286017334598, 1.8910528922722043, 0.3770692712257362), (0.9686789852144178, -0.11799318194450922, 0.2458234957974394, 2.110624902377178, 0.46619869488977506), (0.9265794207714954, -0.10647873653685723, 0.24187661169997865, 2.138332557292695, 0.41648664120393775), (0.9970849186305982, 0.017872970800694346, 0.17640542027473766, 2.09172624548546, 0.4257298615238472), (1.0510350226447782, -0.07145411094814384, 0.1703142076622899, 2.0174490039978026, 0.40168291234338244), (1.1109050235573796, -0.08640300116799549, 0.17428669743842537, 1.952016444359065, 0.38128428703657063), (1.0580421400723503, -0.09641653513944819, 0.17360219531766374, 2.003587923327576, 0.38700076731763455)], NamedTuple{(:logprior, :cost),Tuple{Float64,Float64}}[(logprior = -2.380575383004687, cost = 0.10902652199284729), (logprior = -2.4142322388608655, cost = 0.045989150876917344), (logprior = -2.3903980131656573, cost = 0.1098869437117901), (logprior = -2.4030025791020293, cost = 0.0470837346139897), (logprior = -2.3841017396993203, cost = 0.040754526547590306), (logprior = -2.497618216359245, cost = 0.2231361231320443), (logprior = -2.397747918850516, cost = 0.03217747032280031), (logprior = -2.397077867145681, cost = 0.046756486288005515), (logprior = -2.4322003932034066, cost = 0.035585145045159326), (logprior = -2.4039351465106957, cost = 0.049258032152400474)  …  (logprior = -2.3969210849715226, cost = 0.038747994225126425), (logprior = -2.3799146342259783, cost = 0.04362766075888844), (logprior = -2.3993574991100246, cost = 0.045707387632559854), (logprior = -2.4294755742654073, cost = 0.049827430521755894), (logprior = -2.3717042019327117, cost = 0.03993572880867207), (logprior = -2.3954180781070322, cost = 0.04942271824605218), (logprior = -2.389434883595551, cost = 0.018806498603615343), (logprior = -2.4065559485322554, cost = 0.03715508025300216), (logprior = -2.4251486549323666, cost = 0.04355582960948784), (logprior = -2.4195494510215054, cost = 0.044854997152262065)])</code></pre><p>let&#39;s see the median and 95% confidence interval for the inferred parameters and let&#39;s compare them with the true values</p><pre><code class="language-julia">getstats(V) =
    (median = median(V), lowerbound = quantile(V, 0.025), upperbound = quantile(V, 0.975));

labels = (:μ_1, :μ_2, :σ_1, :σ_2, :prob)
P = [getindex.(res, i) for i = 1:5]
stats = getstats.(P)

for is in eachindex(stats)
    println(labels[is], &quot; ≡ &quot;, parameters[is], &quot; → &quot;, stats[is])
end</code></pre><pre><code class="language-none">μ_1 ≡ 1.0 → (median = 1.0146557332777197, lowerbound = 0.9216173221341698, upperbound = 1.1244369124328315)
μ_2 ≡ 0.0 → (median = -0.06348476814082238, lowerbound = -0.745643609285744, upperbound = 0.035487104965523104)
σ_1 ≡ 0.2 → (median = 0.21097982026518855, lowerbound = 0.13571843164387307, upperbound = 0.512578804325887)
σ_2 ≡ 2.0 → (median = 2.049124788180749, lowerbound = 1.7412187373201575, upperbound = 2.2089239884505334)
prob ≡ 0.4 → (median = 0.4139849522513841, lowerbound = 0.34676176840949563, upperbound = 0.601933990217719)</code></pre><p>The inferred parameters are close to nominal values</p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Basic Usage</a><a class="docs-footer-nextpage" href="../reference/">Reference »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 1 July 2020 13:16">Wednesday 1 July 2020</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
