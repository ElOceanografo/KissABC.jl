<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Example: Gaussian Mixture · KissABC.jl</title><link rel="canonical" href="https://juliaapproxinference.github.io/KissABC.jl/example_1/"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.11.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit">KissABC.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Basic Usage</a></li><li class="is-active"><a class="tocitem" href>Example: Gaussian Mixture</a></li><li><a class="tocitem" href="../reference/">Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Example: Gaussian Mixture</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Example: Gaussian Mixture</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/JuliaApproxInference/KissABC.jl/blob/master/docs/literate/example_1.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="A-gaussian-mixture-model"><a class="docs-heading-anchor" href="#A-gaussian-mixture-model">A gaussian mixture model</a><a id="A-gaussian-mixture-model-1"></a><a class="docs-heading-anchor-permalink" href="#A-gaussian-mixture-model" title="Permalink"></a></h1><p>First of all we define our model,</p><pre><code class="language-julia">using KissABC
using Distributions

function model(P, N)
    μ_1, μ_2, σ_1, σ_2, prob = P
    d1 = randn(N) .* σ_1 .+ μ_1
    d2 = randn(N) .* σ_2 .+ μ_2
    ps = rand(N) .&lt; prob
    R = zeros(N)
    R[ps] .= d1[ps]
    R[.!ps] .= d2[.!ps]
    R
end</code></pre><pre><code class="language-none">model (generic function with 1 method)</code></pre><p>Let&#39;s use the model to generate some data, this data will constitute our dataset</p><pre><code class="language-julia">parameters = (1.0, 0.0, 0.2, 2.0, 0.4)
data = model(parameters, 5000)</code></pre><pre><code class="language-none">5000-element Array{Float64,1}:
  0.6116040514903484
  2.1525747496889887
  1.1147756623711944
  1.018725420634428
  0.09119460534712649
  1.111903803715734
  2.8282584264378157
  2.7900041554426056
 -0.4445902188423748
 -1.4468614338727208
  ⋮
  1.1389015819161008
  0.8642005542263237
  4.3052571867445275
  0.8729659571772115
  1.0360720351361823
  1.037246264939781
  1.3104275374456125
  1.5983561303623612
  1.0094352483874394</code></pre><p>let&#39;s look at the data</p><pre><code class="language-julia">using Plots
histogram(data)
savefig(&quot;ex1_hist1.svg&quot;);</code></pre><p><img src="../ex1_hist1.svg" alt="ex1_hist1"/></p><p>we can now try to infer all parameters using <code>KissABC</code>, first of all we need to define a reasonable prior for our model</p><pre><code class="language-julia">prior = Factored(
    Uniform(0, 2), # there is surely a peak between 0 and 2
    Uniform(-1, 1), #there is a smeared distribution centered around 0
    Uniform(0, 1), # the peak has surely a width below 1
    Uniform(0, 4), # the smeared distribution surely has a width less than 4
    Beta(2, 2), # the number of total events from both distributions look about the same, so we will favor 0.5 just a bit
);</code></pre><p>let&#39;s look at a sample from the prior, to see that it works</p><pre><code class="language-julia">rand(prior)</code></pre><pre><code class="language-none">(1.1847444232150015, 0.7445581230072387, 0.5778932710788496, 1.687907493996116, 0.4402338204027898)</code></pre><p>now we need a function to compute summary statistics for our data, this is not the optimal choice, but it will work out anyway</p><pre><code class="language-julia">function S(x)
    r = (0.1, 0.2, 0.5, 0.8, 0.9)
    quantile(x, r)
end</code></pre><pre><code class="language-none">S (generic function with 1 method)</code></pre><p>we will define a function to use the <code>model</code> and summarize it&#39;s results</p><pre><code class="language-julia">summ_model(P, N) = S(model(P, N));</code></pre><p>now we need a distance function to compare the summary statistics of target data and simulated data</p><pre><code class="language-julia">summ_data = S(data)
D(P, N = 5000) = sqrt(mean(abs2, summ_data .- summ_model(P, N)));</code></pre><p>we can now run ABCDE to get the posterior distribution of our parameters given the dataset <code>data</code></p><pre><code class="language-julia">approx_density = ApproxPosterior(prior, D, 0.05)
res, _ = mcmc(approx_density, nparticles = 100, generations = 500, verbose = 0)</code></pre><pre><code class="language-none">([(0.9866070484920959, -0.013478131763032301, 0.2265568229886103, 1.8976272830709398, 0.34493011429540793), (1.0425804999329764, -0.03577689429531318, 0.20540002473638422, 2.1157468007098643, 0.40045334442001157), (1.0311158633488735, 0.05878600208004661, 0.15799166299150333, 1.9062064418710687, 0.36746137665742673), (1.0445441398929447, 0.055589078117040024, 0.17769635661147068, 1.941554702692812, 0.3694059332099956), (1.039043760667508, 0.014516995428015898, 0.19646010792093155, 1.8892221291712727, 0.3566778211389183), (1.0303622492578945, 0.03045529665011595, 0.15145492895893037, 1.8583296320881493, 0.3304903341587575), (0.9356956413501784, 0.024192946699543253, 0.2814948891464168, 2.100619621748402, 0.402877004887585), (0.945105076380776, 0.09804857518029197, 0.24804090368643977, 2.0406323290552937, 0.36361164386760925), (0.9925756213123891, 0.0030356471966835885, 0.29369733983071405, 2.2092248048141645, 0.4425545149667006), (1.0365296562210824, -0.0699181560988395, 0.29445912271825514, 1.9001604842504636, 0.35659785754198875)  …  (0.9908567005207863, 0.07585767043255098, 0.1924722556216312, 2.0105642908562658, 0.39006329962701963), (0.9117280730333285, 0.00372759247066147, 0.1979850091822308, 1.9037385074888804, 0.3501903034878927), (1.0525810379286977, -0.022083224855985822, 0.194420419755515, 1.9893167969391485, 0.38005482568851734), (0.9563671750570772, -0.05743728092224831, 0.3079518528008207, 2.0418450083013515, 0.4014906369255563), (0.9713344314558079, 0.04921741644715663, 0.205080654806365, 1.8729322679085922, 0.299752100293379), (1.05227827938699, -0.05018579129453665, 0.21477328302893903, 2.0451607397479643, 0.41797504363636717), (1.064941261252508, 0.007801508361403045, 0.22070392245140485, 1.9043999242886818, 0.3270260593836673), (1.0738025839498029, -0.04055558401283815, 0.16851764348025922, 1.9865213180627868, 0.3925553802838252), (1.004247215755966, -0.0815454253656538, 0.2585432235191348, 2.145530108378874, 0.4163418363668223), (1.0706122774900544, 0.015583307958231409, 0.1771479953002636, 1.9065770670528712, 0.3147464362043579)], NamedTuple{(:logprior, :cost),Tuple{Float64,Float64}}[(logprior = -2.468256056047977, cost = 0.0464968729270626), (logprior = -2.4075687489938975, cost = 0.04756949999389201), (logprior = -2.4399803120665045, cost = 0.048703443274501726), (logprior = -2.4377813433572326, cost = 0.033107656270453596), (logprior = -2.452861243933317, cost = 0.04882149313473658), (logprior = -2.489216795797736, cost = 0.04677116716431569), (logprior = -2.405585380265222, cost = 0.04877557956337936), (logprior = -2.444444425511601, cost = 0.04110486598302221), (logprior = -2.3804114425919596, cost = 0.04683456385080299), (logprior = -2.4529611688796944, cost = 0.05047977112374036)  …  (logprior = -2.4166755963841435, cost = 0.03969590453277662), (logprior = -2.4611835345798143, cost = 0.06594932538361613), (logprior = -2.426393244935742, cost = 0.04966650387425417), (logprior = -2.4067134289860146, cost = 0.046777716297869615), (logprior = -2.5419495954881777, cost = 0.04408086587804518), (logprior = -2.3944047572908427, cost = 0.04244451232168456), (logprior = -2.494593343278049, cost = 0.048319365333105664), (logprior = -2.4144011773438945, cost = 0.035848386141644206), (logprior = -2.3955176909002924, cost = 0.04873830892737727), (logprior = -2.5147835248461403, cost = 0.03299488508147659)])</code></pre><p>let&#39;s see the median and 95% confidence interval for the inferred parameters and let&#39;s compare them with the true values</p><pre><code class="language-julia">getstats(V) =
    (median = median(V), lowerbound = quantile(V, 0.025), upperbound = quantile(V, 0.975));

labels = (:μ_1, :μ_2, :σ_1, :σ_2, :prob)
P = [getindex.(res, i) for i = 1:5]
stats = getstats.(P)

for is in eachindex(stats)
    println(labels[is], &quot; ≡ &quot;, parameters[is], &quot; → &quot;, stats[is])
end</code></pre><pre><code class="language-none">μ_1 ≡ 1.0 → (median = 1.0067814897357779, lowerbound = 0.7096637935258135, upperbound = 1.1183606454196104)
μ_2 ≡ 0.0 → (median = 0.015050151693123653, lowerbound = -0.18243148674232196, upperbound = 0.1201403902720034)
σ_1 ≡ 0.2 → (median = 0.20873856039040894, lowerbound = 0.13553880173789393, upperbound = 0.6462712716943534)
σ_2 ≡ 2.0 → (median = 1.983987187119697, lowerbound = 1.8388402513684383, upperbound = 2.2079445708386096)
prob ≡ 0.4 → (median = 0.3721807458437729, lowerbound = 0.31562354323647207, upperbound = 0.5750300165772193)</code></pre><p>The inferred parameters are close to nominal values</p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Basic Usage</a><a class="docs-footer-nextpage" href="../reference/">Reference »</a></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Tuesday 30 June 2020 23:20">Tuesday 30 June 2020</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
